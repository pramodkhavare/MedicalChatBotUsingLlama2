{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "PINECONE_KEY = os.environ['PINECONE_API_KEY']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain.vectorstores import Pinecone \n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "import pinecone\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PINECONE_API_ENV = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Data From Pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data From Pdf Using PyPDFLoader\n",
    "def load_pdf(data_directory):\n",
    "    loader = DirectoryLoader(\n",
    "        path=data_directory ,\n",
    "        glob=\"*.pdf\" ,\n",
    "        loader_cls=PyPDFLoader\n",
    "    )\n",
    "    documents = loader.load() \n",
    "    \n",
    "    return documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_pdf(data_directory=\"D:\\Data Science\\GenAI\\MedicalChatBotUsingLlama2\\Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Data Into Chunksa: -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks_from_data(data):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size =500 ,\n",
    "        chunk_overlap=20\n",
    "    )\n",
    "    splitted_chunk = splitter.split_documents(data)\n",
    "    return splitted_chunk \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = get_chunks_from_data(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6983"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Multimedia Content\\nKelly A. Quin, Editor, Imaging and Multimedia Content\\nLeitha Etheridge-Sims, Mary K. Grimes, Dave Oblender,\\nImage Catalogers\\nPamela A. Reed, Imaging Coordinator\\nRandy Bassett, Imaging Supervisor\\nRobert Duncan, Senior Imaging Specialist\\nDan Newell, Imaging Specialist\\nChristine O’Bryan, Graphic Specialist\\nMaria Franklin, Permissions Manager\\nMargaret A. Chamberlain, Permissions Specialist\\nMichelle DiMercurio, Senior Art Director\\nMike Logusz, Graphic Artist', metadata={'source': 'D:\\\\Data Science\\\\GenAI\\\\MedicalChatBotUsingLlama2\\\\Data\\\\The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf', 'page': 2})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Chunk In Embeddings and Store them In Vector DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddigng_from_huggingface():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = get_embeddigng_from_huggingface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embeddings.embed_query(\"Hello Pramod\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings.embed_query(\"Hello Pramod\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pinecone code\n",
    "# from pinecone import Pinecone \n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_KEY)\n",
    "index_name = \"medicalchatbot\"\n",
    "import time\n",
    "existing_indexes = [\n",
    "    index_info[\"name\"] for index_info in pc.list_indexes()\n",
    "]\n",
    "\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time) \n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name ,\n",
    "        dimension=384 ,\n",
    "        metric='cosine'\n",
    "    )\n",
    "    # wait for index to be initialized\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(index_name)  # Help to connect your index \n",
    "time.sleep(1)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_from_texts = PineconeVectorStore.from_texts(\n",
    "        [t.page_content for t in text_chunks],\n",
    "        index_name=index_name,\n",
    "        embedding=embeddings\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6983\n"
     ]
    }
   ],
   "source": [
    "print(len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_pinecone.vectorstores.PineconeVectorStore"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO Add More Record\n",
    "# vectorstore = PineconeVectorStore(index_name=index_name, embedding=embeddings)\n",
    "# vectorstore.add_texts([\"More text to embed and add to the index!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create embedding from chunk\n",
    "chunk_embedding = [embeddings.embed_query(text.page_content) for text in text_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 7303}},\n",
       " 'total_vector_count': 7303}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6983\n",
      "6983\n"
     ]
    }
   ],
   "source": [
    "print(len(text_chunks))\n",
    "print(len(chunk_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store Those Embeddings into vector\n",
    "#You can use these method as well\n",
    "# vectors = [(str(i), chunk_embedding[i], {'text': text_chunks[i].page_content}) for i in range(len(text_chunks))]\n",
    "# index.upsert(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Feske, eds. New York: Churchill Livingstone, 1996.\\nRichard RobinsonKEY TERMS\\nNerve conduction velocity test —A test of the\\nspeed of conduction of nerves, performed on the\\nnerves in the arm and leg.Evoked responses seeEvoked potential\\nstudies\\nExanthema subitum seeRoseola\\nExercise\\nDefinition\\nExercise is physical activity that is planned, struc-\\ntured, and repetitive for the purpose of conditioning any\\npart of the body. Exercise is utilized to improve health,'), Document(page_content='force. The needle may be repositioned in the same mus-\\ncle for further recording. Other muscles may be tested as\\nwell. A typical session lasts from 30–60 minutes.\\nA slightly different test, the nerve conduction veloci-\\nty test , is often performed at the same time with the same\\nequipment. In this test, stimulating and recording elec-\\ntrodes are used, and small electrical shocks are applied to\\nmeasure the ability of the nerve to conduct electrical sig-'), Document(page_content='formed to measure how fast impulses travel through the\\nnerves. This test may show characteristic features of\\nCMT, but it is not diagnostic of CMT. Nerve conduction\\ntesting may be combined with electromyography\\n(EMG), an electrical test of the muscles.\\nA nerve biopsy (removal of a small piece of the\\nnerve) may be performed to look for changes characteris-\\ntic of CMT. However, this testing is not diagnostic of\\nCMT and is usually not necessary for making a diagnosis.')]\n"
     ]
    }
   ],
   "source": [
    "vectorstore = PineconeVectorStore(index_name=index_name, embedding=embeddings)\n",
    "query = \"What is Nerve conduction testing—?\"\n",
    "docs = vectorstore.similarity_search(query ,k=3)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrive_query(query, k):\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    results = index.query(vector=query_embedding, top_k=k, include_metadata=True)\n",
    "    matching_results = [result['metadata']['text'] for result in results['matches']]\n",
    "    return matching_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Feske, eds. New York: Churchill Livingstone, 1996.\\nRichard RobinsonKEY TERMS\\nNerve conduction velocity test —A test of the\\nspeed of conduction of nerves, performed on the\\nnerves in the arm and leg.Evoked responses seeEvoked potential\\nstudies\\nExanthema subitum seeRoseola\\nExercise\\nDefinition\\nExercise is physical activity that is planned, struc-\\ntured, and repetitive for the purpose of conditioning any\\npart of the body. Exercise is utilized to improve health,',\n",
       " 'force. The needle may be repositioned in the same mus-\\ncle for further recording. Other muscles may be tested as\\nwell. A typical session lasts from 30–60 minutes.\\nA slightly different test, the nerve conduction veloci-\\nty test , is often performed at the same time with the same\\nequipment. In this test, stimulating and recording elec-\\ntrodes are used, and small electrical shocks are applied to\\nmeasure the ability of the nerve to conduct electrical sig-',\n",
       " 'formed to measure how fast impulses travel through the\\nnerves. This test may show characteristic features of\\nCMT, but it is not diagnostic of CMT. Nerve conduction\\ntesting may be combined with electromyography\\n(EMG), an electrical test of the muscles.\\nA nerve biopsy (removal of a small piece of the\\nnerve) may be performed to look for changes characteris-\\ntic of CMT. However, this testing is not diagnostic of\\nCMT and is usually not necessary for making a diagnosis.']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrive_query(query=query ,k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "promt_template = \"\"\"\n",
    "Use the following information to answer the question.\n",
    "If you dont know just say it dont try to make up an answer.\n",
    "\n",
    "context : {context} \n",
    "question : {question}\n",
    "\n",
    "Only helpful answer.\n",
    "Helpful answer: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template= promt_template ,\n",
    "    input_variables=[\"context\" ,\"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CTransformers(\n",
    "    model=r\"D:\\Data Science\\GenAI\\MedicalChatBotUsingLlama2\\model\\llama-2-7b-chat.ggmlv3.q4_0.bin\" ,\n",
    "    model_type = \"llama\" ,\n",
    "    config={\n",
    "        'max_new_tokens' :512 ,\n",
    "        'temperature':0.3\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_pinecone.vectorstores.PineconeVectorStore'>\n",
      "<class 'langchain_pinecone.vectorstores.PineconeVectorStore'>\n"
     ]
    }
   ],
   "source": [
    "print(type(vectorstore_from_texts))\n",
    "print(type(vectorstore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Corticosteroids —A group of anti-inflammatory\\nsubstances often used to treat skin conditions.\\nImmune response —The protective reaction by the\\nimmune system against foreign antigens (sub-\\nstances that the body perceives as potentially dan-\\ngerous). The immune system combats disease by\\nneutralizing or destroying antigens.contact dermatitis becomes a chronic and disabling con-\\ndition that can have a profound effect on employability\\nand quality of life.\\nPrevention'),\n",
       " Document(page_content='ics and personal care products; latex items such as gloves\\nand condoms; and formaldehyde. Many people find that\\nthey are allergic to the nickel in inexpensive jewelry. ACD\\nis usually confined to the area of skin that comes in contact\\nwith the allergen, typically the hands or face. Symptoms\\nrange from mild to severe and resemble those of ICD; a\\npatch test may be needed to determine which kind of con-\\ntact dermatitis a person is suffering from.\\nDiagnosis'),\n",
       " Document(page_content='Corticosteriod —A group of synthetic hormones\\nthat are used to prevent or reduce inflammation.\\nToxic effects may result from rapid withdrawal after\\nprolonged use or from continued use of large doses.\\nPatch test —A skin test that is done to identify aller-\\ngens. A suspected substance is applied to the skin.\\nAfter 24–48 hours, if the area is red and swollen,\\nthe test is positive for that substance. If no reaction\\noccurs, another substance is applied. This is con-')]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qa = RetrievalQA.from_chain_type(\n",
    "#     llm=llm,\n",
    "#     chain_type=\"stuff\",\n",
    "#     retriever=vectorstore_from_texts.as_retriever(search_kwargs={'k': 2}),\n",
    "#     return_source_documents=True,\n",
    "#     chain_type_kwargs=chain_type_kwargs  # Replace with appropriate kwargs for your chain_type\n",
    "# )\n",
    "# qa=RetrievalQA.from_chain_type(\n",
    "#     llm=llm, \n",
    "#     chain_type=\"stuff\", \n",
    "#     retriever=vectorstore.as_retriever(search_kwargs={'k': 2}),\n",
    "#     return_source_documents=True, \n",
    "#     chain_type_kwargs=chain_type_kwargs) \n",
    "\n",
    "query = \"what is acne\"\n",
    "vectorstore.similarity_search(query ,k=3) \n",
    "\n",
    "# query = \"What is Nerve conduction testing—?\"\n",
    "# docs = vectorstore.similarity_search(query ,k=3)\n",
    "# print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrive_query(query, k):\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    results = index.query(vector=query_embedding, top_k=k, include_metadata=True)\n",
    "    matching_results = [result['metadata']['text'] for result in results['matches']]\n",
    "    return matching_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search Answer from Vectors DB \n",
    "def retrive_answers(query):\n",
    "    doc_search = retrive_query(query ,2)\n",
    "    llm = CTransformers(\n",
    "    model=r\"D:\\Data Science\\GenAI\\MedicalChatBotUsingLlama2\\model\\llama-2-7b-chat.ggmlv3.q4_0.bin\" ,\n",
    "    model_type = \"llama\" ,\n",
    "    config={\n",
    "        'max_new_tokens' :512 ,\n",
    "        'temperature':0.3\n",
    "    }\n",
    ")\n",
    "    chain = load_qa_chain(llm=llm ,chain_type='stuff')\n",
    "    response = chain(\n",
    "        {\n",
    "            \"input_documents\" : doc_search ,\n",
    "            \"question\": query\n",
    "        }\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Feske, eds. New York: Churchill Livingstone, 1996.\\nRichard RobinsonKEY TERMS\\nNerve conduction velocity test —A test of the\\nspeed of conduction of nerves, performed on the\\nnerves in the arm and leg.Evoked responses seeEvoked potential\\nstudies\\nExanthema subitum seeRoseola\\nExercise\\nDefinition\\nExercise is physical activity that is planned, struc-\\ntured, and repetitive for the purpose of conditioning any\\npart of the body. Exercise is utilized to improve health,', 'force. The needle may be repositioned in the same mus-\\ncle for further recording. Other muscles may be tested as\\nwell. A typical session lasts from 30–60 minutes.\\nA slightly different test, the nerve conduction veloci-\\nty test , is often performed at the same time with the same\\nequipment. In this test, stimulating and recording elec-\\ntrodes are used, and small electrical shocks are applied to\\nmeasure the ability of the nerve to conduct electrical sig-']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m out_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is Nerve conduction testing—?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mretrive_answers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer)\n",
      "Cell \u001b[1;32mIn[112], line 14\u001b[0m, in \u001b[0;36mretrive_answers\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m      5\u001b[0m     llm \u001b[38;5;241m=\u001b[39m CTransformers(\n\u001b[0;32m      6\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mData Science\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGenAI\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMedicalChatBotUsingLlama2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mllama-2-7b-chat.ggmlv3.q4_0.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m ,\n\u001b[0;32m      7\u001b[0m     model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama\u001b[39m\u001b[38;5;124m\"\u001b[39m ,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     }\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m     chain \u001b[38;5;241m=\u001b[39m load_qa_chain(llm\u001b[38;5;241m=\u001b[39mllm ,chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstuff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_documents\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_search\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32md:\\Data Science\\GenAI\\MedicalChatBotUsingLlama2\\venv\\lib\\site-packages\\langchain\\chains\\base.py:181\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    182\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    183\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    184\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    185\u001b[0m )\n",
      "File \u001b[1;32md:\\Data Science\\GenAI\\MedicalChatBotUsingLlama2\\venv\\lib\\site-packages\\langchain\\chains\\base.py:175\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[0;32m    169\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    170\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    171\u001b[0m     inputs,\n\u001b[0;32m    172\u001b[0m )\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 175\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    178\u001b[0m     )\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32md:\\Data Science\\GenAI\\MedicalChatBotUsingLlama2\\venv\\lib\\site-packages\\langchain\\chains\\combine_documents\\base.py:106\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[0;32m    105\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[1;32m--> 106\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombine_docs(\n\u001b[0;32m    107\u001b[0m     docs, callbacks\u001b[38;5;241m=\u001b[39m_run_manager\u001b[38;5;241m.\u001b[39mget_child(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mother_keys\n\u001b[0;32m    108\u001b[0m )\n\u001b[0;32m    109\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[1;32md:\\Data Science\\GenAI\\MedicalChatBotUsingLlama2\\venv\\lib\\site-packages\\langchain\\chains\\combine_documents\\stuff.py:163\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[1;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_docs\u001b[39m(\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m, docs: List[Document], callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m    151\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[0;32m    152\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Stuff all documents into one prompt and pass to LLM.\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m        element returned is a dictionary of other keys to return.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_inputs(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Call predict on the LLM.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs), {}\n",
      "File \u001b[1;32md:\\Data Science\\GenAI\\MedicalChatBotUsingLlama2\\venv\\lib\\site-packages\\langchain\\chains\\combine_documents\\stuff.py:119\u001b[0m, in \u001b[0;36mStuffDocumentsChain._get_inputs\u001b[1;34m(self, docs, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct inputs from kwargs and docs.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03mFormat and the join all the documents together into one input with name\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    dictionary of inputs to LLMChain\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Format each document according to the prompt\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m doc_strings \u001b[38;5;241m=\u001b[39m [format_document(doc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocument_prompt) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# Join the documents together to put them in the prompt.\u001b[39;00m\n\u001b[0;32m    121\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    122\u001b[0m     k: v\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39minput_variables\n\u001b[0;32m    125\u001b[0m }\n",
      "File \u001b[1;32md:\\Data Science\\GenAI\\MedicalChatBotUsingLlama2\\venv\\lib\\site-packages\\langchain\\chains\\combine_documents\\stuff.py:119\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct inputs from kwargs and docs.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03mFormat and the join all the documents together into one input with name\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    dictionary of inputs to LLMChain\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Format each document according to the prompt\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m doc_strings \u001b[38;5;241m=\u001b[39m [\u001b[43mformat_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocument_prompt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# Join the documents together to put them in the prompt.\u001b[39;00m\n\u001b[0;32m    121\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    122\u001b[0m     k: v\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39minput_variables\n\u001b[0;32m    125\u001b[0m }\n",
      "File \u001b[1;32md:\\Data Science\\GenAI\\MedicalChatBotUsingLlama2\\venv\\lib\\site-packages\\langchain\\schema\\prompt_template.py:177\u001b[0m, in \u001b[0;36mformat_document\u001b[1;34m(doc, prompt)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_document\u001b[39m(doc: Document, prompt: BasePromptTemplate) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    145\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format a document into a string based on a prompt template.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m    First, this pulls information from the document from two sources:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m            >>> \"Page 1: This is a joke\"\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m     base_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage_content\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdoc\u001b[38;5;241m.\u001b[39mmetadata}\n\u001b[0;32m    178\u001b[0m     missing_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(prompt\u001b[38;5;241m.\u001b[39minput_variables)\u001b[38;5;241m.\u001b[39mdifference(base_info)\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_metadata) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "out_query = \"What is Nerve conduction testing—?\"\n",
    "answer = retrive_answers(out_query)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
